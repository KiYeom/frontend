//ê°„ë‹¨íˆ viewì™€ textê°€ ìˆëŠ” í˜ì´ì§€
import React, { useEffect, useState, useRef } from 'react';
import { View, Text, Button } from 'react-native';
import { useSafeAreaInsets } from 'react-native-safe-area-context';
import { useTranslation } from 'react-i18next';
import { useNavigation } from '@react-navigation/native';
import MyModule from '../../../modules/my-module';
import {
  initSocket,
  connectSocket,
  disconnectSocket,
  //sendMicAudio,
  getSocket,
} from './socketManager';
import { getAccessToken } from '../../utils/storageUtils';
import { EventEmitter } from 'expo-modules-core';
import float32ToInt16PCM from './float32ToInt16PCM';
import SimpleWaveform from './SimpleWaveform';
import {
  endAudioCall,
  pauseAudioCall,
  resumeAudioCall,
  startAudioCall,
  heartbeatAudioCall,
} from '../../apis/voice';
const CallPage: React.FC = () => {
  const [samples, setSamples] = useState<number[]>([]);
  const [responseText, setResponseText] = useState<string>('');
  const [realTimeData, setRealTimeData] = useState('');
  const [waveform, setWaveform] = useState<number[]>([]);
  const heartbeatTimer = useRef<NodeJS.Timeout | null>(null);
  const [wavFilePath, setWavFilePath] = useState<string | null>(null);
  const lastAudioRoute = useRef<string | null>(null);
  // ğŸŸ¢ ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ê°ì§€ ìƒíƒœ ì¶”ê°€
  const [isAudioSessionActive, setIsAudioSessionActive] = useState(false);
  const isAudioSessionActiveRef = useRef(false);

  const setAudioSessionActive = (active: boolean) => {
    console.log('setAudioSessionActive í˜¸ì¶œ ì‹œì‘:', isAudioSessionActiveRef.current);
    setIsAudioSessionActive(active);
    isAudioSessionActiveRef.current = active;
    console.log('setAudioSessionActive í˜¸ì¶œ ì¢…ë£Œ:', isAudioSessionActiveRef.current);
  };

  useEffect(() => {
    const userToken = getAccessToken();
    initSocket(userToken);
  }, []);

  useEffect(() => {
    const emitter = new EventEmitter(MyModule);
    // ğŸŸ¡ ì‹œê°í™”ìš© ì´ë²¤íŠ¸
    const sub = emitter.addListener('onAudioBuffer', (event) => {
      const samples: number[] = event.samples;
      // íŒŒí˜•ìœ¼ë¡œ ë³€í™˜: ì ˆëŒ“ê°’ë§Œ ì¶”ì¶œ, 50ê°œë§Œ ìë¦„
      const normalized = samples.slice(0, 50).map((n) => Math.min(Math.abs(n), 1));
      setWaveform(normalized);

      //sendMicAudio(samples);
    });
    // âœ…  (PCM ì „ì†¡ìš©)
    const micSub = emitter.addListener('onMicAudio', ({ pcm }) => {
      //console.log('ğŸ“¥ Received mic PCM data!', pcm); // âœ… ë‚´ê°€ ë§í•œ ê±° JSë¡œ
      //console.log('ğŸ“¥ Received mic PCM data!'); // âœ… ë‚´ê°€ ë§í•œ ê±° JSë¡œ
      const socket = getSocket();
      // ì†Œì¼“ì— ì—°ê²°ëœ ê²½ìš° : ë§ˆì´í¬ ì˜¤ë””ì˜¤ ì„œë²„ì— ì „ì†¡
      if (socket && socket.connected) {
        const payload = new Uint8Array(pcm);
        socket.emit('mic_audio', payload);
        //console.log('ğŸ“¤ mic_audio ì „ì†¡ë¨:', payload.length, 'bytes');
      } else {
        console.log('âŒ ì†Œì¼“ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. mic_audio ì „ì†¡ ì‹¤íŒ¨');
      }
    });
    // íŒŒì¼ ê²½ë¡œ ë°›ê¸°
    const fileListener = emitter.addListener('onRecordingSaved', ({ filePath }) => {
      console.log('ğŸ“ WAV íŒŒì¼ ì €ì¥ë¨:', filePath);
      setWavFilePath(filePath); // ìƒíƒœ ì €ì¥
      // ì˜ˆ: íŒŒì¼ ê²½ë¡œë¥¼ í”Œë ˆì´ì–´ì— ë„˜ê¸°ê±°ë‚˜ ìƒíƒœì— ì €ì¥
      // setWavPath(filePath);
    });
    const readySub = emitter.addListener('onRecordingReady', () => {
      console.log('ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ!');
      setAudioSessionActive(true);
      readySub.remove();
    });
    // ì—ì–´íŒŸ <-> ìŠ¤í”¼ì»¤
    const subscription = emitter.addListener('onAudioRouteChange', (event) => {
      const newRoute = event?.newRoute;
      // ìƒˆ ê²½ë¡œê°€ ì´ì „ê³¼ ê°™ìœ¼ë©´ ë¬´ì‹œ
      console.log('âœ… ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ê°ì§€:', newRoute);
      console.log('ğŸ¾ í˜„ì¬ ì˜¤ë””ì˜¤ ê²½ë¡œ:', lastAudioRoute.current);
      if (lastAudioRoute.current === null) {
        console.log('ğŸŸ¡ ì´ˆê¸° ì˜¤ë””ì˜¤ ê²½ë¡œ ì„¤ì • ë¬´ì‹œ');
        lastAudioRoute.current = newRoute;
        return;
      }
      if (lastAudioRoute.current === newRoute) {
        console.log('ğŸ” ë™ì¼í•œ ì˜¤ë””ì˜¤ ê²½ë¡œ - ì²˜ë¦¬ ìƒëµ');
        return;
      }
      lastAudioRoute.current = newRoute;

      if (isAudioSessionActiveRef.current) {
        console.log('í™œì„± ìƒíƒœ - ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ì²˜ë¦¬');
        handlePause();
      } else {
        console.log('ë¹„í™œì„± ìƒíƒœ - ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ë¬´ì‹œ');
      }
    });

    return () => {
      sub.remove();
      micSub.remove();
      fileListener.remove();
      subscription.remove();
      MyModule.stopRecording?.(); // ì •ë¦¬
    };
  }, []);
  //console.log('mymodule', MyModule);

  //ì‹œì‘
  const handleConnect = async () => {
    const socket = getSocket();
    if (!socket) return;

    // 1. ì†Œì¼“ ì—°ê²°
    socket.connect();

    // 2. ì†Œì¼“ ì—°ê²° ì™„ë£Œ í›„ì— start + ë§ˆì´í¬ + í•˜íŠ¸ë¹„íŠ¸
    socket.once('connect', async () => {
      try {
        console.log('1. API í˜¸ì¶œ ì‹œì‘');
        await startAudioCall(); // API í˜¸ì¶œ (ì„œë²„ì— start ì•Œë¦¼)
        console.log('2. startAudioCall ì‘ë‹µ ë°›ê³  ë§ˆì´í¬ ì‹œì‘');
        MyModule.startRecording(); // ë§ˆì´í¬ ì‹œì‘
        console.log('3. ë§ˆì´í¬ ì‹œì‘ ì™„ë£Œ, í•˜íŠ¸ë¹„íŠ¸ ì‹œì‘');
        startHeartbeat(); // í•˜íŠ¸ë¹„íŠ¸ ì‹œì‘
        //console.log('4. ì‹¤ì‹œê°„ ì¬ìƒ ì‹œì‘');
        //MyModule.playNextChunk(); // ì²« ë²ˆì§¸ ìŒì„± ë°ì´í„° ì „ì†¡ (í•„ìš”ì‹œ)
        //console.log('5. ì˜¤ë””ì˜¤ ì„¸ì…˜ í™œì„±í™”');
        console.log('4ï¸âƒ£. startAudioCall ì™„ë£Œ');
      } catch (err) {
        console.error('âŒ startAudioCall ì‹¤íŒ¨:', err);
      }
    });
  };

  //ì†Œì¼“ ì—°ê²° í•´ì œ (í”„ë¡ íŠ¸ëŠ” ë¨¼ì € ì†Œì¼“ ì—°ê²°ì„ ëŠì§€ ì•ŠëŠ”ë‹¤)
  const handleDisconnect = async () => {
    try {
      const response = await endAudioCall(); //1. ì„œë²„ì— ì¢…ë£Œ ìš”ì²­
    } catch (err) {
      console.error('âŒ endAudioCall ì‹¤íŒ¨:', err);
    } finally {
      MyModule.stopRecording(); //2. ë§ˆì´í¬ ì¤‘ì§€
      MyModule.stopRealtimePlayback(); //3. ì¬ìƒ ì¤‘ì§€
      stopHeartbeat(); // 3. í•˜íŠ¸ë¹„íŠ¸ ì¤‘ì§€
    }
  };

  //ì¼ì‹œ ì¤‘ì§€
  const handlePause = async () => {
    console.log('handlePause í˜¸ì¶œ');
    try {
      const response = await pauseAudioCall();
      console.log('âœ… pauseRecording ì‘ë‹µ:', response);
      //pause ì¸ ë™ì•ˆì€ ìŒì„± ì „ì†¡ì„ í•˜ë©´ ì•ˆ ë¨
      MyModule.stopRecording(); // ë…¹ìŒ ì¤‘ì§€
      MyModule.pauseRealtimePlayback(); // ì¶œë ¥ ì •ì§€ (ë²„í¼ ë³´ì¡´)
      // ì†Œì¼“ ì—°ê²°ì€ ìœ ì§€
    } catch (err) {
      console.error('âŒ pauseRecording ì‹¤íŒ¨:', err);
    }
  };

  //ë‹¤ì‹œì‹œì‘í•˜ê¸° (resume)
  const handleResume = async () => {
    console.log('handleResume í˜¸ì¶œ');
    try {
      const response = await resumeAudioCall();
      console.log('âœ… resumeRecording ì‘ë‹µ:', response);
      MyModule.startRecording(); // ë§ˆì´í¬ ì¬ì‹œì‘
      MyModule.resumeRealtimePlayback(); // ì¶œë ¥ ì¬ê°œ (ë²„í¼ ê³„ì† ì¬ìƒ)
      //startHeartbeat(); // í•˜íŠ¸ë¹„íŠ¸ ì¬ì‹œì‘
    } catch (err) {
      console.error('âŒ resumeRecording ì‹¤íŒ¨:', err);
    }
  };

  //5ì´ˆë™ì•ˆ í•˜íŠ¸ë¹„íŠ¸ ì‹œì‘
  const startHeartbeat = () => {
    if (heartbeatTimer.current) return;

    heartbeatTimer.current = setInterval(async () => {
      try {
        await heartbeatAudioCall();
        //console.log('âœ… Heartbeat sent');
      } catch (e) {
        //console.warn('âŒ Heartbeat failed:', e.message);
      }
    }, 5000); // 5ì´ˆ ê°„ê²©
  };

  const stopHeartbeat = () => {
    console.log('í•˜íŠ¸ ë¹„íŠ¸ ì¤‘ì§€');
    if (heartbeatTimer.current) {
      clearInterval(heartbeatTimer.current);
      heartbeatTimer.current = null;
      console.log('âœ… Heartbeat stopped');
    }
  };

  return (
    <View style={{ paddingTop: 100 }}>
      <Text>{MyModule.hello()}</Text>
      <SimpleWaveform data={waveform} width={360} height={80} />
      <Button title="ì‹œì‘(ì›¹ì†Œì¼“ ì—°ê²° í›„ ì„œë²„ API í˜¸ì¶œ)" onPress={handleConnect} />
      <Button title="ëŠê¸°(ìŒì„± í†µí™” ì¢…ë£Œí•˜ê¸° API í˜¸ì¶œ" onPress={handleDisconnect} />
      <Button title="ì¼ì‹œì¤‘ì§€(pause)" onPress={handlePause} />
      <Button title="ë‹¤ì‹œì‹œì‘í•˜ê¸°(resume)" onPress={handleResume} />
      <Button title="í…ŒìŠ¤íŠ¸" onPress={() => console.log('hi')} />
      <Text style={{ fontFamily: 'Courier', fontSize: 12 }}>
        {samples.map((n) => n.toFixed(2)).join(', ')}
      </Text>
      <Text style={{ marginTop: 20, fontSize: 16 }}>ğŸ¤– Gemini: {responseText}</Text>
    </View>
  );
};

export default CallPage;
