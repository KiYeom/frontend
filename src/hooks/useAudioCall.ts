// hooks/useAudioCall.ts
import { useEffect, useState, useRef, useCallback } from 'react';
import { EventEmitter } from 'expo-modules-core';
import MyModule from '../../modules/my-module';
import { getAccessToken } from '../utils/storageUtils';
import { initSocket, getSocket } from '../pages/CallPage/socketManager';
import { setTextReceiveHandler } from '../pages/CallPage/socketManager';
import {
  endAudioCall,
  pauseAudioCall,
  resumeAudioCall,
  startAudioCall,
  heartbeatAudioCall,
  getRemainingTime,
} from '../apis/voice';

export enum CallStatus {
  Idle = 'idle',
  Start = 'start',
  Paused = 'pause',
  Resumed = 'resume',
  End = 'end',
  Active = 'acrtive',
}

interface AudioCallState {
  waveform: number[];
  wavFilePath: string | null;
  isAudioSessionActive: boolean;
  remainingTime: number;
  totalTime: number;
  responseText: string;
  callStatus: CallStatus;
  volumeLevel: number; // ë³¼ë¥¨ ë ˆë²¨ ì¶”ê°€
  speakerVolume: number; // ìƒëŒ€ë°© ë³¼ë¥¨ ì¶”ê°€
}

interface AudioCallHandlers {
  handleConnect: () => Promise<void>;
  handleDisconnect: () => Promise<void>;
  handlePause: () => Promise<void>;
  handleResume: () => Promise<void>;
}

export const useAudioCall = (): [AudioCallState, AudioCallHandlers] => {
  // State
  const [waveform, setWaveform] = useState<number[]>([]);
  const [wavFilePath, setWavFilePath] = useState<string | null>(null);
  const [isAudioSessionActive, setIsAudioSessionActive] = useState(false);
  const [remainingTime, setRemainingTime] = useState<number>(0);
  const [totalTime, setTotalTime] = useState<number>(0);
  const [responseText, setResponseText] = useState<string>('');
  const [callStatus, setCallStatus] = useState<CallStatus>(CallStatus.Idle);
  //ë³¼ë¥¨ ìƒíƒœ
  const [volumeLevel, setVolumeLevel] = useState<number>(0); //ë‚˜ì˜ ë³¼ë¥¨
  const [speakerVolume, setSpeakerVolume] = useState<number>(0); //ìƒëŒ€ë°© (ì¿ í‚¤) ë³¼ë¥¨

  // ë³¼ë¥¨ ê³„ì‚° í•¨ìˆ˜
  function calculateVolume(pcm: Uint8Array): number {
    if (pcm.length < 2) return 0;

    const view = new DataView(pcm.buffer);
    let sumSquares = 0;
    const sampleCount = pcm.length / 2;

    for (let i = 0; i < pcm.length; i += 2) {
      const sample = view.getInt16(i, true); // ë¦¬í‹€ì—”ë””ì•ˆ
      sumSquares += sample * sample;
    }

    const rms = Math.sqrt(sumSquares / sampleCount);
    const normalized = rms / 32768; // Int16 max value
    return Math.min(normalized, 1); // 0~1ë¡œ ì •ê·œí™”
  }

  // Refs
  const isAudioSessionActiveRef = useRef(false);
  const lastAudioRoute = useRef<string | null>(null);
  const heartbeatTimer = useRef<NodeJS.Timeout | null>(null);
  const countdownTimer = useRef<NodeJS.Timeout | null>(null);

  // Helper function
  const setAudioSessionActive = useCallback((active: boolean) => {
    console.log('setAudioSessionActive í˜¸ì¶œ:', active);
    setIsAudioSessionActive(active);
    isAudioSessionActiveRef.current = active;
  }, []);

  /** í…ìŠ¤íŠ¸ ìˆ˜ì‹ ì‹œë§ˆë‹¤ ìµœì‹  ë¬¸ì¥ìœ¼ë¡œ êµì²´ (ì›í•˜ë©´ ëˆ„ì ë„ ê°€ëŠ¥) */
  useEffect(() => {
    console.log('ğŸ”¹ í…ìŠ¤íŠ¸ ìˆ˜ì‹  í•¸ë“¤ëŸ¬ ì„¤ì •');
    setTextReceiveHandler((text) => {
      setResponseText(text); // ğŸ”¹ â€œêµì²´â€ ë°©ì‹
      // setResponseText((prev) => prev + '\n' + text); // â† â€œëˆ„ì â€ì´ í•„ìš”í•˜ë©´ ì´ ì¤„ë¡œ
    });
  }, []);

  // Socket initialization
  useEffect(() => {
    const userToken = getAccessToken();
    initSocket(userToken);
  }, []);

  // ê¸°ì¡´ useEffectì™€ ë³„ê°œë¡œ ì¶”ê°€
  useEffect(() => {
    const loadTotalTime = async () => {
      try {
        const data = await getRemainingTime();
        console.log('â±ï¸ ì´ í†µí™” ì‹œê°„ ë¶ˆëŸ¬ì˜´:', data.remainingTime, 'ì´ˆ');
        setTotalTime(data.remainingTime);
        setRemainingTime(data.remainingTime); // ì´ ì‹œì ì— remainingTimeë„ ì´ˆê¸°í™” ê°€ëŠ¥
      } catch (err) {
        console.error('âŒ ì´ í†µí™” ì‹œê°„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:', err);
      }
    };

    loadTotalTime();
  }, []);

  // Event listeners setup
  useEffect(() => {
    const emitter = new EventEmitter(MyModule);

    // ì‹œê°í™”ìš© ì´ë²¤íŠ¸
    const audioBufferSub = emitter.addListener('onAudioBuffer', (event) => {
      const samples: number[] = event.samples;
      const normalized = samples.slice(0, 50).map((n) => Math.min(Math.abs(n), 1));
      setWaveform(normalized);
      console.log('ğŸ”Š ì˜¤ë””ì˜¤ ë²„í¼ ì´ë²¤íŠ¸ ìˆ˜ì‹ :', normalized);
    });

    // PCM ì „ì†¡ìš©
    const micSub = emitter.addListener('onMicAudio', ({ pcm }) => {
      const socket = getSocket();
      if (socket && socket.connected) {
        const payload = new Uint8Array(pcm);
        socket.emit('mic_audio', payload);

        // 1. ë³¼ë¥¨ ê³„ì‚°
        const uint8 = new Uint8Array(pcm);
        const volume = calculateVolume(uint8);
        setVolumeLevel(volume);
      } else {
        console.log('âŒ ì†Œì¼“ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. mic_audio ì „ì†¡ ì‹¤íŒ¨');
      }
    });

    //íŒŒí˜• ë°›ê¸°
    emitter.addListener('onPlaybackFrame', ({ level }) => {
      console.log('ğŸ”ˆ Playback volume:', level);
      //setSpeakerVolume(volume); // ì‹œê°í™” ìš©ë„ë¡œ ì „ë‹¬
    });

    // íŒŒì¼ ê²½ë¡œ ë°›ê¸°
    const fileListener = emitter.addListener('onRecordingSaved', ({ filePath }) => {
      console.log('ğŸ“ WAV íŒŒì¼ ì €ì¥ë¨:', filePath);
      setWavFilePath(filePath);
    });

    const readySub = emitter.addListener('onRecordingReady', () => {
      console.log('ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ!');
      setAudioSessionActive(true);
      readySub.remove();
    });

    // ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ê°ì§€
    const routeChangeSub = emitter.addListener('onAudioRouteChange', (event) => {
      const newRoute = event?.newRoute;
      console.log('âœ… ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ê°ì§€:', newRoute);

      if (lastAudioRoute.current === null) {
        lastAudioRoute.current = newRoute;
        return;
      }

      if (lastAudioRoute.current === newRoute) {
        console.log('ğŸ” ë™ì¼í•œ ì˜¤ë””ì˜¤ ê²½ë¡œ - ì²˜ë¦¬ ìƒëµ');
        return;
      }

      lastAudioRoute.current = newRoute;

      if (isAudioSessionActiveRef.current) {
        console.log('í™œì„± ìƒíƒœ - ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ì²˜ë¦¬');
        handlePause();
      }
    });

    return () => {
      audioBufferSub.remove();
      micSub.remove();
      fileListener.remove();
      routeChangeSub.remove();
      MyModule.stopRecording?.();
      if (countdownTimer.current) {
        clearInterval(countdownTimer.current);
      }
    };
  }, []);

  // Heartbeat management
  const startHeartbeat = useCallback(() => {
    if (heartbeatTimer.current) return;

    heartbeatTimer.current = setInterval(async () => {
      try {
        const data = await heartbeatAudioCall();
        //console.log('ğŸ’“ Heartbeat ì‘ë‹µ:', data);
        setRemainingTime(data.remainingTime);
      } catch (e) {
        console.warn('âŒ Heartbeat failed:', e.message);
      }
    }, 5000);
  }, []);

  const stopHeartbeat = useCallback(() => {
    if (heartbeatTimer.current) {
      clearInterval(heartbeatTimer.current);
      heartbeatTimer.current = null;
      console.log('âœ… Heartbeat stopped');
    }
  }, []);
  //useEffect(() => {
  //console.log('ë‚¨ì€ ì‹œê°„ ë³€í™” : ', remainingTime, 'ì´ˆ');
  //}, [remainingTime]);

  // Countdown management
  const startCountdown = useCallback(() => {
    console.log('ğŸš€ startCountdown ì§„ì…');
    console.log('ğŸ§­ countdownTimer.current ìƒíƒœ:', countdownTimer.current);
    if (countdownTimer.current) {
      console.log('ğŸ” ì´ë¯¸ ì¹´ìš´íŠ¸ë‹¤ìš´ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.');
      return;
    }
    console.log('â³ ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘');

    countdownTimer.current = setInterval(() => {
      //console.log('â²ï¸ ì¹´ìš´íŠ¸ë‹¤ìš´ tick');
      setRemainingTime((prev) => {
        const next = Math.max(prev - 1, 0); //í…ŒìŠ¤íŠ¸ : 10ì´ˆì”© ê°ì†Œ
        //console.log('ğŸ• remainingTime ì—…ë°ì´íŠ¸:', prev, 'â†’', next);
        return Math.max(prev - 1, 0);
      });
    }, 1000);
  }, []);

  const stopCountdown = useCallback(() => {
    if (countdownTimer.current) {
      clearInterval(countdownTimer.current);
      countdownTimer.current = null;
    }
  }, []);

  // Handler functions
  const handleConnect = useCallback(async () => {
    const socket = getSocket();
    console.log('ğŸ”¹ handleConnect í˜¸ì¶œ:', socket?.connected);
    if (!socket) return;

    socket.connect();

    socket.once('connect', async () => {
      try {
        console.log('1. API í˜¸ì¶œ ì‹œì‘');
        const response = await startAudioCall();
        console.log('âœ… startAudioCall ì‘ë‹µ:', response);
        setCallStatus(CallStatus.Start);
        console.log('2. startAudioCall ì‘ë‹µ ë°›ê³  ë§ˆì´í¬ ì‹œì‘');
        MyModule.startRecording();
        console.log('3. ë§ˆì´í¬ ì‹œì‘ ì™„ë£Œ, í•˜íŠ¸ë¹„íŠ¸ ì‹œì‘');
        startHeartbeat();
        startCountdown();
        console.log('4ï¸âƒ£. startAudioCall ì™„ë£Œ');
      } catch (err) {
        console.error('âŒ startAudioCall ì‹¤íŒ¨:', err);
        setCallStatus(CallStatus.Idle);
      }
    });
  }, [startHeartbeat, startCountdown]);

  const handleDisconnect = useCallback(async () => {
    try {
      const response = await endAudioCall();
      console.log('âœ… handleDisconnect ì‘ë‹µ:', response);
      setCallStatus(CallStatus.End);
    } catch (err) {
      console.error('âŒ endAudioCall ì‹¤íŒ¨:', err);
    } finally {
      MyModule.stopRecording();
      MyModule.stopRealtimePlayback();
      stopHeartbeat();
      stopCountdown();
      setCallStatus(CallStatus.Idle);
    }
  }, [stopHeartbeat, stopCountdown]);

  const handlePause = useCallback(async () => {
    console.log('handlePause í˜¸ì¶œ', callStatus);
    try {
      const response = await pauseAudioCall();
      console.log('âœ… pauseRecording ì‘ë‹µ:', response);
      setCallStatus(CallStatus.Paused);
      MyModule.stopRecording();
      MyModule.pauseRealtimePlayback();
      stopCountdown();
    } catch (err) {
      console.error('âŒ pauseRecording ì‹¤íŒ¨:', err);
    }
  }, [stopCountdown]);

  const handleResume = useCallback(async () => {
    console.log('handleResume í˜¸ì¶œ');
    try {
      const response = await resumeAudioCall();
      console.log('âœ… resumeRecording ì‘ë‹µ:', response);
      if (typeof response.remainingTime === 'number') {
        console.log('handleResume ë‚¨ì€ ì‹œê°„ ì—…ë°ì´íŠ¸:', response.remainingTime, 'ì´ˆ');
        setRemainingTime(response.remainingTime); // âœ… ìƒíƒœ ê°±ì‹  ì¶”ê°€
      }
      setCallStatus(CallStatus.Resumed);
      startCountdown(); // ì¹´ìš´íŠ¸ë‹¤ìš´ ì¬ì‹œì‘
      console.log('â³ ì¹´ìš´íŠ¸ë‹¤ìš´ ì¬ì‹œì‘');

      MyModule.startRecording();
      MyModule.resumeRealtimePlayback();
    } catch (err) {
      console.error('âŒ resumeRecording ì‹¤íŒ¨:', err);
    }
  }, [startCountdown]);

  useEffect(() => {
    return () => {
      console.log('ğŸ§¨ useAudioCall ì–¸ë§ˆìš´íŠ¸ë¨');
    };
  }, []);

  return [
    {
      waveform,
      wavFilePath,
      isAudioSessionActive,
      remainingTime,
      totalTime,
      responseText,
      callStatus,
      volumeLevel, // ë³¼ë¥¨ ë ˆë²¨ ì¶”ê°€
      speakerVolume, // ìƒëŒ€ë°© ë³¼ë¥¨ ì¶”ê°€
    },
    {
      handleConnect,
      handleDisconnect,
      handlePause,
      handleResume,
    },
  ];
};
