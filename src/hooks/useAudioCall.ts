// hooks/useAudioCall.ts
import { useEffect, useState, useRef, useCallback } from 'react';
import { Platform } from 'react-native';
import { EventEmitter } from 'expo-modules-core';
import MyModule from '../../modules/my-module';
import { getAccessToken } from '../utils/storageUtils';
import { initSocket, getSocket } from '../pages/voice/socketManager';
import { setTextReceiveHandler } from '../pages/voice/socketManager';
import { getUserNickname } from '../utils/storageUtils';
import {
  endAudioCall,
  pauseAudioCall,
  resumeAudioCall,
  startAudioCall,
  heartbeatAudioCall,
  getRemainingTime,
} from '@apis/voice';

export enum CallStatus {
  Idle = 'idle',
  Start = 'start',
  Paused = 'pause',
  Resumed = 'resume',
  End = 'end',
  Active = 'acrtive',
  CONNECTING = 'connecting',
  ERROR = 'error',
}

const userNickname = getUserNickname(); // ì‚¬ìš©ì ë‹‰ë„¤ì„ ê°€ì ¸ì˜¤ê¸°
// ìƒíƒœë³„ ê¸°ë³¸ ë©”ì‹œì§€ ìƒìˆ˜
const STATUS_MESSAGES = {
  [CallStatus.Idle]: `ì°¾ì•„ì™€ì¤˜ì„œ ê³ ë§ˆì›Œìš”${userNickname ? `, ${userNickname}ë‹˜` : ''}\në§ˆìŒ ì†ì˜ ìƒê°ì„ í¸í•˜ê²Œ ì´ì•¼ê¸° í•´ ì£¼ì„¸ìš”`,
  [CallStatus.Start]: 'ì¿ í‚¤ê°€ ë“£ê³  ìˆì–´ìš”',
  [CallStatus.Paused]: 'ì ì‹œ ë©ˆì·„ì–´ìš”. ì¤€ë¹„ë˜ë©´ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”',
  [CallStatus.Resumed]: 'ë‹¤ì‹œ ë“¤ì„ê²Œìš”',
  [CallStatus.End]: 'ë‹¤ìŒì— ë˜ ì´ì•¼ê¸°í•´ìš” ğŸ˜Š',
  [CallStatus.CONNECTING]: 'ì—°ê²° ì¤‘ì´ì—ìš”...',
  [CallStatus.ERROR]: 'ì—°ê²°ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”',
};

interface AudioCallState {
  waveform: number[];
  wavFilePath: string | null;
  isAudioSessionActive: boolean;
  remainingTime: number;
  totalTime: number;
  responseText: string;
  callStatus: CallStatus;
  volumeLevel: number; // ë³¼ë¥¨ ë ˆë²¨ ì¶”ê°€
  speakerVolume: number; // ìƒëŒ€ë°© ë³¼ë¥¨ ì¶”ê°€
}

interface AudioCallHandlers {
  handleConnect: () => Promise<void>;
  handleDisconnect: () => Promise<void>;
  handlePause: () => Promise<void>;
  handleResume: () => Promise<void>;
  setTotalTime: (seconds: number) => void;
  setRemainingTime: (seconds: number) => void;
}

const GAIN_CORRECTION = 20; // ì‹¤í—˜ì ìœ¼ë¡œ ì¡°ì •, 10~25 ì •ë„
const THRESHOLD = 0.00015; // 0.0001~0.0002
export const useAudioCall = (): [AudioCallState, AudioCallHandlers] => {
  // State
  const [waveform, setWaveform] = useState<number[]>([]);
  const [wavFilePath, setWavFilePath] = useState<string | null>(null);
  const [isAudioSessionActive, setIsAudioSessionActive] = useState(false);
  const [remainingTime, setRemainingTime] = useState<number>(0);
  const [totalTime, setTotalTime] = useState<number>(0);
  const [responseText, setResponseText] = useState<string>('');
  const [callStatus, setCallStatus] = useState<CallStatus>(CallStatus.Idle);
  //ë³¼ë¥¨ ìƒíƒœ
  const [volumeLevel, setVolumeLevel] = useState<number>(0); //ë‚˜ì˜ ë³¼ë¥¨
  const [speakerVolume, setSpeakerVolume] = useState<number>(0); //ìƒëŒ€ë°© (ì¿ í‚¤) ë³¼ë¥¨

  // ë³¼ë¥¨ ê³„ì‚° í•¨ìˆ˜
  function calculateVolume(pcm: Uint8Array): number {
    if (pcm.length < 2) return 0;

    const view = new DataView(pcm.buffer);
    let sumSquares = 0;
    const sampleCount = pcm.length / 2;

    for (let i = 0; i < pcm.length; i += 2) {
      const sample = view.getInt16(i, true); // ë¦¬í‹€ì—”ë””ì•ˆ
      sumSquares += sample * sample;
    }

    const rms = Math.sqrt(sumSquares / sampleCount);
    const normalized = rms / 32768; // Int16 max value
    const boosted = normalized * GAIN_CORRECTION;
    return boosted < THRESHOLD ? 0 : Math.min(boosted, 1);
    //return Math.min(normalized, 1); // 0~1ë¡œ ì •ê·œí™”
  }

  // Refs
  const isAudioSessionActiveRef = useRef(false);
  const lastAudioRoute = useRef<string | null>(null);
  const heartbeatTimer = useRef<NodeJS.Timeout | null>(null);
  const countdownTimer = useRef<NodeJS.Timeout | null>(null);

  // Helper function
  const setAudioSessionActive = useCallback((active: boolean) => {
    console.log('setAudioSessionActive í˜¸ì¶œ:', active);
    setIsAudioSessionActive(active);
    isAudioSessionActiveRef.current = active;
  }, []);

  /** í…ìŠ¤íŠ¸ ìˆ˜ì‹ ì‹œë§ˆë‹¤ ìµœì‹  ë¬¸ì¥ìœ¼ë¡œ êµì²´ (ì›í•˜ë©´ ëˆ„ì ë„ ê°€ëŠ¥) */
  useEffect(() => {
    console.log('ğŸ”¹ í…ìŠ¤íŠ¸ ìˆ˜ì‹  í•¸ë“¤ëŸ¬ ì„¤ì •');
    setTextReceiveHandler((text) => {
      setResponseText(text); // ğŸ”¹ â€œêµì²´â€ ë°©ì‹
      // setResponseText((prev) => prev + '\n' + text); // â† â€œëˆ„ì â€ì´ í•„ìš”í•˜ë©´ ì´ ì¤„ë¡œ
    });
  }, []);

  // Socket initialization
  useEffect(() => {
    const userToken = getAccessToken();
    initSocket(userToken);
  }, []);

  // ê¸°ì¡´ useEffectì™€ ë³„ê°œë¡œ ì¶”ê°€
  useEffect(() => {
    const loadTotalTime = async () => {
      try {
        const data = await getRemainingTime();
        console.log('â±ï¸ ì´ í†µí™” ì‹œê°„ ë¶ˆëŸ¬ì˜´:', data.remainingTime, 'ì´ˆ');
        setTotalTime(data.remainingTime);
        setRemainingTime(data.remainingTime); // ì´ ì‹œì ì— remainingTimeë„ ì´ˆê¸°í™” ê°€ëŠ¥
      } catch (err) {
        console.error('âŒ ì´ í†µí™” ì‹œê°„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:', err);
      }
    };

    loadTotalTime();
  }, []);

  // Event listeners setup
  useEffect(() => {
    const emitter = new EventEmitter(MyModule);

    // ì‹œê°í™”ìš© ì´ë²¤íŠ¸
    const audioBufferSub = emitter.addListener('onAudioBuffer', (event) => {
      const samples: number[] = event.samples;
      const normalized = samples.slice(0, 50).map((n) => Math.min(Math.abs(n), 1));
      setWaveform(normalized);
      console.log('ğŸ”Š ì˜¤ë””ì˜¤ ë²„í¼ ì´ë²¤íŠ¸ ìˆ˜ì‹ :', normalized);
    });

    // PCM ì „ì†¡ìš©
    const micSub = emitter.addListener('onMicAudio', ({ pcm }) => {
      const socket = getSocket();
      if (socket && socket.connected) {
        const payload = new Uint8Array(pcm);
        socket.emit('mic_audio', payload);

        // 1. ë³¼ë¥¨ ê³„ì‚°
        const uint8 = new Uint8Array(pcm);
        const volume = calculateVolume(uint8);
        //console.log('volume', volume);
        setVolumeLevel(volume);
      } else {
        console.log('âŒ ì†Œì¼“ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. mic_audio ì „ì†¡ ì‹¤íŒ¨');
      }
    });

    //íŒŒí˜• ë°›ê¸°
    /*emitter.addListener('onPlaybackFrame', ({ level }) => {
      console.log('ğŸ”ˆ Playback volume:', level);
      //setSpeakerVolume(volume); // ì‹œê°í™” ìš©ë„ë¡œ ì „ë‹¬
    });*/

    // íŒŒì¼ ê²½ë¡œ ë°›ê¸°
    /*const fileListener = emitter.addListener('onRecordingSaved', ({ filePath }) => {
      console.log('ğŸ“ WAV íŒŒì¼ ì €ì¥ë¨:', filePath);
      setWavFilePath(filePath);
    });*/

    const readySub = emitter.addListener('onRecordingReady', () => {
      console.log('ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ!');
      setAudioSessionActive(true);
      readySub.remove();
    });

    // ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ê°ì§€
    const routeChangeSub = emitter.addListener('onAudioRouteChange', (event) => {
      const newRoute = event?.newRoute;
      console.log('âœ… ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ê°ì§€:', newRoute);

      if (lastAudioRoute.current === null) {
        lastAudioRoute.current = newRoute;
        return;
      }

      if (lastAudioRoute.current === newRoute) {
        console.log('ğŸ” ë™ì¼í•œ ì˜¤ë””ì˜¤ ê²½ë¡œ - ì²˜ë¦¬ ìƒëµ');
        return;
      }

      lastAudioRoute.current = newRoute;

      if (isAudioSessionActiveRef.current) {
        console.log('í™œì„± ìƒíƒœ - ì˜¤ë””ì˜¤ ê²½ë¡œ ë³€ê²½ ì²˜ë¦¬');
        handlePause();
      }
    });

    return () => {
      audioBufferSub.remove();
      micSub.remove();
      //fileListener.remove();
      routeChangeSub.remove();
      MyModule.stopRecording?.();
      if (countdownTimer.current) {
        clearInterval(countdownTimer.current);
      }
    };
  }, []);

  // Heartbeat management
  const startHeartbeat = useCallback(() => {
    if (heartbeatTimer.current) return;

    heartbeatTimer.current = setInterval(async () => {
      try {
        const data = await heartbeatAudioCall();
        //console.log('ğŸ’“ Heartbeat ì‘ë‹µ:', data);
        setRemainingTime(data.remainingTime);
      } catch (e) {
        console.warn('âŒ Heartbeat failed:', e.message);
      }
    }, 5000);
  }, []);

  const stopHeartbeat = useCallback(() => {
    if (heartbeatTimer.current) {
      clearInterval(heartbeatTimer.current);
      heartbeatTimer.current = null;
      console.log('âœ… Heartbeat stopped');
    }
  }, []);
  //useEffect(() => {
  //console.log('ë‚¨ì€ ì‹œê°„ ë³€í™” : ', remainingTime, 'ì´ˆ');
  //}, [remainingTime]);

  // Countdown management
  const startCountdown = useCallback(() => {
    console.log('ğŸš€ startCountdown ì§„ì…');
    console.log('ğŸ§­ countdownTimer.current ìƒíƒœ:', countdownTimer.current);
    if (countdownTimer.current) {
      console.log('ğŸ” ì´ë¯¸ ì¹´ìš´íŠ¸ë‹¤ìš´ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.');
      return;
    }
    console.log('â³ ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘');

    countdownTimer.current = setInterval(() => {
      //console.log('â²ï¸ ì¹´ìš´íŠ¸ë‹¤ìš´ tick');
      setRemainingTime((prev) => {
        const next = Math.max(prev - 1, 0); //í…ŒìŠ¤íŠ¸ : 10ì´ˆì”© ê°ì†Œ
        //console.log('ğŸ• remainingTime ì—…ë°ì´íŠ¸:', prev, 'â†’', next);
        return Math.max(prev - 1, 0);
      });
    }, 1000);
  }, []);

  const stopCountdown = useCallback(() => {
    if (countdownTimer.current) {
      clearInterval(countdownTimer.current);
      countdownTimer.current = null;
    }
  }, []);

  // Handler functions
  const handleConnect = useCallback(async () => {
    const socket = getSocket();
    console.log('ğŸ”¹ handleConnect í˜¸ì¶œ:', socket?.connected);
    setCallStatus(CallStatus.CONNECTING);
    setResponseText(STATUS_MESSAGES[CallStatus.CONNECTING]); //ì—°ê²° ì¤‘ì´ì—ìš”...
    if (!socket) return;

    socket.connect();

    socket.once('connect', async () => {
      try {
        console.log('1. API í˜¸ì¶œ ì‹œì‘');
        const response = await startAudioCall();
        console.log('âœ… startAudioCall ì‘ë‹µ:', response);
        setCallStatus(CallStatus.Start);
        console.log('2. startAudioCall ì‘ë‹µ ë°›ê³  ë§ˆì´í¬ ì‹œì‘');
        MyModule.startRecording();
        console.log('3. ë§ˆì´í¬ ì‹œì‘ ì™„ë£Œ, í•˜íŠ¸ë¹„íŠ¸ ì‹œì‘');
        startHeartbeat();
        startCountdown();
        console.log('4ï¸âƒ£. startAudioCall ì™„ë£Œ');
        setResponseText(STATUS_MESSAGES[CallStatus.Start]); // ì¿ í‚¤ê°€ ë“£ê³  ìˆì–´ìš”
      } catch (err) {
        console.error('âŒ startAudioCall ì‹¤íŒ¨:', err);
        setCallStatus(CallStatus.Idle);
        setResponseText(STATUS_MESSAGES[CallStatus.ERROR]); // ì—°ê²°ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
      }
    });
  }, [startHeartbeat, startCountdown]);

  const handleDisconnect = useCallback(async () => {
    try {
      const response = await endAudioCall();
      console.log('âœ… handleDisconnect ì‘ë‹µ:', response);
      setCallStatus(CallStatus.End);
      setResponseText(STATUS_MESSAGES[CallStatus.End]); // ë‹¤ìŒì— ë˜ ì´ì•¼ê¸°í•´ìš” ğŸ˜Š
    } catch (err) {
      console.error('âŒ endAudioCall ì‹¤íŒ¨:', err);
      setResponseText(STATUS_MESSAGES[CallStatus.ERROR]); // ì—°ê²°ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”
    } finally {
      MyModule.stopRecording();
      MyModule.stopRealtimePlayback();
      stopHeartbeat();
      stopCountdown();
      setCallStatus(CallStatus.Idle); // ìƒíƒœ ì´ˆê¸°í™”
    }
  }, [stopHeartbeat, stopCountdown]);

  const handlePause = useCallback(async () => {
    console.log('handlePause í˜¸ì¶œ', callStatus);
    try {
      const response = await pauseAudioCall();
      console.log('âœ… pauseRecording ì‘ë‹µ:', response);
      setCallStatus(CallStatus.Paused);
      MyModule.stopRecording();
      MyModule.pauseRealtimePlayback();
      stopCountdown();
    } catch (err) {
      console.error('âŒ pauseRecording ì‹¤íŒ¨:', err);
    }
  }, [stopCountdown]);

  const handleResume = useCallback(async () => {
    console.log('handleResume í˜¸ì¶œ');
    try {
      const response = await resumeAudioCall();
      console.log('âœ… resumeRecording ì‘ë‹µ:', response);
      if (typeof response.remainingTime === 'number') {
        console.log('handleResume ë‚¨ì€ ì‹œê°„ ì—…ë°ì´íŠ¸:', response.remainingTime, 'ì´ˆ');
        setRemainingTime(response.remainingTime); // âœ… ìƒíƒœ ê°±ì‹  ì¶”ê°€
      }
      setCallStatus(CallStatus.Resumed);
      startCountdown(); // ì¹´ìš´íŠ¸ë‹¤ìš´ ì¬ì‹œì‘
      console.log('â³ ì¹´ìš´íŠ¸ë‹¤ìš´ ì¬ì‹œì‘');
      MyModule.resumeRealtimePlayback();
      //MyModule.startRecording();
      // í”Œë«í¼ë³„ ì²˜ë¦¬
      if (Platform.OS === 'ios') {
        // iOSëŠ” ë§ˆì´í¬ ìˆ˜ë™ ì‹œì‘ í•„ìš”
        MyModule.startRecording();
        MyModule.resumeRealtimePlayback();
      } else {
        // AndroidëŠ” ìë™ ì œì–´ì— ë§¡ê¹€
        MyModule.resumeRealtimePlayback();
      }
    } catch (err) {
      console.error('âŒ resumeRecording ì‹¤íŒ¨:', err);
    }
  }, [startCountdown]);

  useEffect(() => {
    return () => {
      console.log('ğŸ§¨ useAudioCall ì–¸ë§ˆìš´íŠ¸ë¨');
      stopCountdown(); // ì´ ë¶€ë¶„ ì¶”ê°€
      stopHeartbeat(); // ì´ ë¶€ë¶„ë„ ì¶”ê°€
    };
  }, [stopCountdown, stopHeartbeat]);

  return [
    {
      waveform,
      wavFilePath,
      isAudioSessionActive,
      remainingTime,
      totalTime,
      responseText,
      callStatus,
      volumeLevel, // ë³¼ë¥¨ ë ˆë²¨ ì¶”ê°€
      speakerVolume, // ìƒëŒ€ë°© ë³¼ë¥¨ ì¶”ê°€
    },
    {
      handleConnect,
      handleDisconnect,
      handlePause,
      handleResume,
      setTotalTime,
      setRemainingTime,
    },
  ];
};
