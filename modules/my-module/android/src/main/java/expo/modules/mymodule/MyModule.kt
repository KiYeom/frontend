package expo.modules.mymodule

import android.content.Context
import android.content.pm.PackageManager
import android.media.*
import android.util.Log
import expo.modules.kotlin.modules.Module
import expo.modules.kotlin.modules.ModuleDefinition
import kotlinx.coroutines.*
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.util.concurrent.ConcurrentLinkedQueue
import android.media.audiofx.AcousticEchoCanceler

class MyModule : Module() {
  enum class MicState {
    IDLE,
    RECORDING,
    MUTED_AUTO,
    MUTED_MANUAL
  }
  @Volatile private var micState = MicState.IDLE
  @Volatile private var waitingForPrebuffer = true
  private val BUF_PER_SEC = 15
  private val sampleRate = 24000
  private val channels = 1
  private val maxQueueLength = 100
  private val fadeLength = 64
  private val maxSilenceFrames = 1024

  private var audioTrack: AudioTrack? = null
  private var audioRecord: AudioRecord? = null
  private var isPlaying = false
  private var isFirstBlock = true
  private var silenceFramesGenerated = 0
  private var previousSample: Float = 0f

  private val pcmBufferQueue: ConcurrentLinkedQueue<ByteArray> = ConcurrentLinkedQueue()
  private val taggedBufferQueue: ConcurrentLinkedQueue<TaggedAudio> = ConcurrentLinkedQueue()

  private var playbackJob: Job? = null
  private var recordJob: Job? = null
  private var micAutoControlJob: Job? = null

  private var currentPCMData: ShortArray? = null
  private var currentDataLength: Int = 0
  private var currentReadPosition: Int = 0

  //@Volatile private var isRecording = false
  private var micManuallyMuted = false

  private var lastPlaybackEventTime = System.currentTimeMillis()

  private val minBuffersToStart = 2 


  data class TaggedAudio(val data: ByteArray, val isSilent: Boolean)

  override fun definition() = ModuleDefinition {
    Name("MyModule")

    Constants("BUF_PER_SEC" to BUF_PER_SEC)

    Events("onChange", "onAudioBuffer", "onMicAudio", "onRecordingSaved", "onAudioRouteChange", "onRecordingReady")

    Function("startRecording") { startRecording() }
    Function("stopRecording") { stopRecording() }
    Function("startRealtimePlayback") { startRealtimePlayback() }
    Function("stopRealtimePlayback") { stopRealtimePlayback() }
    Function("streamPCMData") { data: ByteArray -> streamPCMData(data) }
    Function("playPCMBuffer") { data: ByteArray -> playPCMBuffer(data) }
    Function("pauseRealtimePlayback") { pauseRealtimePlayback() }
    Function("resumeRealtimePlayback") { resumeRealtimePlayback() }
    Function("hello") { "Hello world! ğŸ‘‹" }
  }

  private fun hasRecordAudioPermission(): Boolean {
    val context = appContext.reactContext
    return context?.checkSelfPermission(android.Manifest.permission.RECORD_AUDIO) ==
      PackageManager.PERMISSION_GRANTED
  }

  private fun startRealtimePlayback() {
    Log.d("MyModule", "â–¶ï¸ startRealtimePlayback() í˜¸ì¶œë¨")
    muteMicrophone()

    // âœ… AudioTrackë§Œ ì´ˆê¸°í™”í•˜ê³  ì¬ìƒì€ í•˜ì§€ ì•ŠìŒ
    val bufferSize = AudioTrack.getMinBufferSize(sampleRate, AudioFormat.CHANNEL_OUT_MONO, AudioFormat.ENCODING_PCM_16BIT)
    val actualBufferSize = maxOf(bufferSize, sampleRate / 10)

    audioTrack = AudioTrack(
      AudioManager.STREAM_MUSIC,
      sampleRate,
      AudioFormat.CHANNEL_OUT_MONO,
      AudioFormat.ENCODING_PCM_16BIT,
      actualBufferSize,
      AudioTrack.MODE_STREAM
    )

    // âœ… ì¬ìƒì€ ë²„í¼ê°€ ì¶©ë¶„íˆ ìŒ“ì¼ ë•Œê¹Œì§€ ëŒ€ê¸°
    isPlaying = false
    waitingForPrebuffer = true
  }

  private fun resumeRealtimePlayback() {
    Log.d("MyModule", "ğŸ”„ resumeRealtimePlayback() ì‹œì‘")
    audioTrack?.play()
    val hasAudioBuffers = taggedBufferQueue.any { !it.isSilent }
    Log.d("MyModule", "ğŸ“Š ë²„í¼ ìƒíƒœ - ìŒì„± ë²„í¼ ì¡´ì¬: $hasAudioBuffers, í í¬ê¸°: ${taggedBufferQueue.size}")
    // MUTED_MANUAL ìƒíƒœë¥¼ MUTED_AUTOë¡œ ë³€ê²½
    if (micState == MicState.MUTED_MANUAL || micState == MicState.IDLE) {
      micState = MicState.MUTED_AUTO
      Log.d("MyModule", "ğŸ”„ micStateë¥¼ MUTED_AUTOë¡œ ë³€ê²½ (ì´ì „: $micState)")
    }
    if (playbackJob == null || !playbackJob!!.isActive) {
      Log.d("MyModule", "ğŸµ ìƒˆë¡œìš´ playbackJob ì‹œì‘")
      isPlaying = true
      playbackJob = CoroutineScope(Dispatchers.IO).launch {
        val frameSize = 1024
        val outputBuffer = ShortArray(frameSize)
        while (isPlaying) {
          val samplesWritten = renderAudioFrames(outputBuffer, frameSize)
          if (samplesWritten > 0) {
            audioTrack?.write(outputBuffer, 0, samplesWritten)
          } else {
            delay(5)
          }
        }
      }
    } else {
      Log.d("MyModule", "â™»ï¸ ê¸°ì¡´ playbackJob ì¬ì‚¬ìš©")
      isPlaying = true
    }
    Log.d("MyModule", "ğŸ¯ startMicAutoController í˜¸ì¶œ ì „ - micAutoControlJob: ${micAutoControlJob?.isActive}, isPlaying: $isPlaying")
    startMicAutoController()
  }

  private fun pauseRealtimePlayback() {
    Log.d("MyModule", "â¸ï¸ pauseRealtimePlayback() ì‹œì‘ - í˜„ì¬ micState: $micState")
    isPlaying = false
    audioTrack?.pause()
    Log.d("MyModule", "ğŸ›‘ micAutoControlJob ì·¨ì†Œ")
    micAutoControlJob?.cancel()

    if (micState == MicState.RECORDING) {
      stopRecording()
      micState = MicState.MUTED_MANUAL
      Log.d("MyModule", "ğŸ”š ìˆ˜ë™ìœ¼ë¡œ ë§ˆì´í¬ ëë‚´ì§€ê¸°")
    }
    Log.d("MyModule", "ğŸ“Š ì¼ì‹œì •ì§€ ì‹œ ë²„í¼ ìƒíƒœ - pcm: ${pcmBufferQueue.size}, tagged: ${taggedBufferQueue.size}")
  }

  private fun stopRealtimePlayback() {
    Log.d("MyModule", "â¹ï¸ stopRealtimePlayback() í˜¸ì¶œë¨")
    isPlaying = false
    playbackJob?.cancel()
    micAutoControlJob?.cancel()
    audioTrack?.stop()
    audioTrack?.release()
    audioTrack = null
    playbackJob = null
    micAutoControlJob = null
    pcmBufferQueue.clear()
    taggedBufferQueue.clear()
    currentPCMData = null
    currentReadPosition = 0
    currentDataLength = 0
    isFirstBlock = true
    silenceFramesGenerated = 0

    unmuteMicrophone()
    waitingForPrebuffer = true
  }

  private fun streamPCMData(data: ByteArray) {
    if (data.isEmpty() || data.size % 2 != 0) return

    if (pcmBufferQueue.size < maxQueueLength) {
      val isSilent = isSilentBuffer(data)
      taggedBufferQueue.offer(TaggedAudio(data, isSilent))
      pcmBufferQueue.offer(data)
      silenceFramesGenerated = 0
      Log.d("MyModule", "ğŸ“¡ ${if (isSilent) "ë¬´ìŒ" else "ìŒì„±"} ë²„í¼ ì¶”ê°€ë¨ (${data.size} bytes) - í˜„ì¬ í í¬ê¸°: ${pcmBufferQueue.size}")

      // âœ… ë²„í¼ê°€ ì¶©ë¶„íˆ ìŒ“ì´ê³  ëŒ€ê¸° ì¤‘ì´ë©´ ìë™ ì‹œì‘
      if (waitingForPrebuffer && pcmBufferQueue.size >= minBuffersToStart) {
        waitingForPrebuffer = false
        Log.d("MyModule", "âœ… ë²„í¼ ${pcmBufferQueue.size}ê°œ í™•ë³´ â†’ ì¬ìƒ ì‹œì‘")
        
        // AudioTrack ì¤€ë¹„ ë° ì¬ìƒ ì‹œì‘
        audioTrack?.play()
        isPlaying = true

        playbackJob = CoroutineScope(Dispatchers.IO).launch {
          val frameSize = 1024
          val outputBuffer = ShortArray(frameSize)
          while (isPlaying) {
            val samplesWritten = renderAudioFrames(outputBuffer, frameSize)
            if (samplesWritten > 0) {
              audioTrack?.write(outputBuffer, 0, samplesWritten)
            } else {
              delay(5)
            }
          }
        }

        startMicAutoController()
      }
    } else {
      Log.w("MyModule", "âš ï¸ ë²„í¼ ê°€ë“ ì°¸ â†’ ìƒˆ ë°ì´í„° ë¬´ì‹œ")
    }
  }

  private fun playPCMBuffer(data: ByteArray) {
    Log.d("MyModule", "ğŸ§ playPCMBuffer í˜¸ì¶œë¨ (${data.size} bytes)")
    
    // âœ… AudioTrackì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    if (audioTrack == null) {
      startRealtimePlayback()
    }
    
    // âœ… ë°ì´í„°ë¥¼ íì— ì¶”ê°€ (streamPCMDataê°€ ìë™ìœ¼ë¡œ ì¬ìƒ ì‹œì‘ì„ ì²˜ë¦¬)
    streamPCMData(data)
  }

  private fun renderAudioFrames(outputBuffer: ShortArray, frameCount: Int): Int {
    if (!isPlaying) return 0
    var samplesProvided = 0
    var accumulatedEnergy = 0.0

    for (frame in 0 until frameCount) {
      var sample: Float = 0f
      var hasData = false

      if (currentPCMData == null || currentReadPosition >= currentDataLength) {
        loadNextBuffer()
      }

      currentPCMData?.let { pcmData ->
        if (currentReadPosition < currentDataLength) {
          val int16Sample = pcmData[currentReadPosition]
          sample = int16Sample / 32768f
          currentReadPosition++
          hasData = true
          samplesProvided++
          sample = sample.coerceIn(-0.95f, 0.95f)
          silenceFramesGenerated = 0
        }
      }

      if (!hasData) {
        sample = if (silenceFramesGenerated < maxSilenceFrames) {
          silenceFramesGenerated++
          0f
        } else {
          previousSample * 0.95f
        }
      }

      if (isFirstBlock && frame < fadeLength) {
        sample *= frame.toFloat() / fadeLength
      }

      outputBuffer[frame] = (sample * 32767).toInt().toShort()
      previousSample = sample
      accumulatedEnergy += (sample * sample)
    }

    if (isFirstBlock && samplesProvided > 0) {
      isFirstBlock = false
      Log.d("MyModule", "ğŸµ ì²« ë²ˆì§¸ ì˜¤ë””ì˜¤ ë¸”ë¡ ì¬ìƒ ì‹œì‘")
    }
    
    val rms = kotlin.math.sqrt(accumulatedEnergy / frameCount)
    val now = System.currentTimeMillis()
    if (rms > 0.0002 && now - lastPlaybackEventTime > 16) {
      emit("onPlaybackFrame", mapOf("level" to rms))
      lastPlaybackEventTime = now
    }

    return frameCount
  }

  private fun loadNextBuffer() {
    currentPCMData = null

    if (pcmBufferQueue.isEmpty()) {
      val silenceSampleCount = sampleRate / BUF_PER_SEC
      val silenceBuffer = ByteArray(silenceSampleCount * 2)
      pcmBufferQueue.offer(silenceBuffer)
      taggedBufferQueue.offer(TaggedAudio(silenceBuffer, true))
      //Log.d("MyModule", "ğŸ¤« ë²„í¼ ì—†ìŒ â†’ ë¬´ìŒ ì¶”ê°€ë¨ (${silenceBuffer.size} bytes)")
    }

    val nextData = pcmBufferQueue.poll() ?: return
    val sampleCount = nextData.size / 2

    if (sampleCount <= 0) {
      Log.w("MyModule", "âš ï¸ ë¹ˆ PCM ë°ì´í„° ê±´ë„ˆëœ€")
      currentDataLength = 0
      currentReadPosition = 0
      return
    }

    val byteBuffer = ByteBuffer.wrap(nextData).order(ByteOrder.LITTLE_ENDIAN)
    currentPCMData = ShortArray(sampleCount)
    byteBuffer.asShortBuffer().get(currentPCMData!!)

    currentDataLength = sampleCount
    currentReadPosition = 0

    Log.d("MyModule", "ğŸ”„ ìƒˆ ë²„í¼ ë¡œë“œ: $sampleCount ìƒ˜í”Œ (${nextData.size} bytes)")
  }

  private fun isSilentBuffer(data: ByteArray): Boolean {

    val shortBuffer = ShortArray(data.size / 2)
    ByteBuffer.wrap(data).order(ByteOrder.LITTLE_ENDIAN).asShortBuffer().get(shortBuffer)

    val rms = shortBuffer
      .map { it.toFloat() / 32768f }
      .map { it * it }
      .average()
    Log.d("MyModule", "isSilentBuffer ë°˜í™˜ê°’ : ${rms < 0.0002}")
    return rms < 0.0002
  }

  private fun startMicAutoController() {
    // ê¸°ì¡´ Jobì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì·¨ì†Œ
    if (micAutoControlJob?.isActive == true) {
      Log.d("MyModule", "âš ï¸ ê¸°ì¡´ micAutoControlJob í™œì„±í™” ì¤‘ - ì·¨ì†Œ í›„ ì¬ì‹œì‘")
      micAutoControlJob?.cancel()
    }
    micAutoControlJob = CoroutineScope(Dispatchers.Default).launch {
      var silentCounter = 0
      val silentThreshold = 5
      Log.d("MyModule", "ğŸ§  startMicAutoController ë£¨í”„ ì‹œì‘ë¨")
      while (isPlaying) {
        val tagged = taggedBufferQueue.poll()
        if (tagged != null) {
          Log.d("MyModule", "tagged.isSilent : ${tagged.isSilent}")
          if (tagged.isSilent) {
            silentCounter++
            //Log.d("MyModule", "ğŸ¤« ë¬´ìŒ ê°ì§€ë¨ ($silentCounter / $silentThreshold)")
            if (silentCounter >= silentThreshold && micState == MicState.MUTED_AUTO) {
              Log.d("MyModule", "ğŸ”Š ë¬´ìŒ ì§€ì† â†’ ë§ˆì´í¬ ìë™ ì¼œì§ ì‹œë„")
              unmuteMicrophone()
            }
          } else {
            Log.d("MyModule", "ğŸ¤ ìŒì„± ê°ì§€ë¨")
            if (micState == MicState.RECORDING) {
              Log.d("MyModule", "ğŸ”‡ ìŒì„± ê°ì§€ â†’ ë§ˆì´í¬ ìë™ ë” ì‹œë„")
              muteMicrophone()
            }
            silentCounter = 0
          }
        } else {
          Log.d("MyModule", "ğŸ“­ taggedBufferQueue ë¹„ì–´ ìˆìŒ")
        }
        delay(50)
      }
    }
  }

  private fun startRecording() {
    if (!hasRecordAudioPermission()) {
      Log.e("MyModule", "âŒ RECORD_AUDIO ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
      emit("onMicAudio", mapOf("error" to "permission_denied"))
      return
    }
    if (micState == MicState.RECORDING) {
      Log.d("MyModule", "âš ï¸ ì´ë¯¸ ë…¼ìŒ ì¤‘")
      return
    }

    val minBuffer = AudioRecord.getMinBufferSize(16000, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT)
    audioRecord = AudioRecord(
      MediaRecorder.AudioSource.VOICE_COMMUNICATION,
      16000,
      AudioFormat.CHANNEL_IN_MONO,
      AudioFormat.ENCODING_PCM_16BIT,
      minBuffer
    )
    if (AcousticEchoCanceler.isAvailable()) {
      AcousticEchoCanceler.create(audioRecord!!.audioSessionId)?.enabled = true
      Log.d("MyModule", "ğŸ”‡ AEC í™œì„±í™”ë¨")
    }
    audioRecord?.startRecording()
    micState = MicState.RECORDING
    emit("onRecordingReady", emptyMap<String, Any?>())
    recordJob = CoroutineScope(Dispatchers.IO).launch {
      val buffer = ByteArray(1024)
      while (isActive && micState == MicState.RECORDING) {
        val localRecorder = audioRecord
        if (localRecorder == null) {
          Log.w("MyModule", "âš ï¸ audioRecord is null â€” ë£¨í”„ ì¤‘ë‹¨")
          break
        }

        val read = localRecorder.read(buffer, 0, buffer.size, AudioRecord.READ_NON_BLOCKING)
        //Log.d("MyModule", "ğŸ¹ read=$read, micState=$micState")
        if (read > 0) {
          emit("onMicAudio", mapOf("pcm" to buffer.copyOf(read)))
        }
      }
      Log.d("MyModule", "ğŸ§µ recordJob ë£¨í”„ ì¢…ë£Œ")
    }
  }
  
  private fun stopRecording() {
    Log.d("MyModule", "ğŸ”µ stopRecording() í˜¸ì¶œë¨, ì´ì „ ìƒíƒœ: $micState")

    try {
      audioRecord?.stop()
      audioRecord?.release()
    } catch (e: Exception) {
      Log.e("MyModule", "âŒ ë§ˆì´í¬ ì¤‘ì§• ì‹¤íŒ¨: ${e.message}")
    }

    recordJob?.cancel()
    audioRecord = null
    micState = MicState.IDLE

    Log.d("MyModule", "ğŸš© ë§ˆì´í¬ ìƒíƒœ â†’ IDLE")
  }

  private fun muteMicrophone() {
    if (micState == MicState.RECORDING) {
      stopRecording()
      micState = MicState.MUTED_AUTO
      Log.d("MyModule", "ğŸ”‡ ìë™ ìŒì†Œê±°")
    }
  }

  private fun unmuteMicrophone() {
    Log.d("MyModule", "ğŸ™ï¸ unmuteMicrophone() í˜¸ì¶œ - í˜„ì¬ ìƒíƒœ: $micState")
    if (micState == MicState.MUTED_AUTO) {
      Log.d("MyModule", "âœ… MUTED_AUTO ìƒíƒœ í™•ì¸ â†’ ë§ˆì´í¬ ì‹œì‘")
      startRecording()
      micState = MicState.RECORDING
      Log.d("MyModule", "ğŸ™ï¸ ìë™ìœ¼ë¡œ ë§ˆì´í¬ ì¬ì‹œì‘")
    } else {
      Log.d("MyModule", "ğŸ™…ï¸ ìˆ˜ë™ ìŒì†Œê±° ìƒíƒœì´ë¡œ ì¬ì‹œì‘ ì•ˆí•¨..")
    }
  }
  
  private fun emit(event: String, data: Any?) {
    try {
      when (data) {
        is Map<*, *> -> {
          @Suppress("UNCHECKED_CAST")
          sendEvent(event, data as Map<String, Any?>)
        }
        null -> sendEvent(event, mapOf<String, Any?>())
        else -> sendEvent(event, mapOf("value" to data))
      }
    } catch (e: Exception) {
      e.printStackTrace()
    }
  }
}